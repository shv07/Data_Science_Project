{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYyrMiX3tY38"
   },
   "outputs": [],
   "source": [
    "# references\n",
    "# https://las.inf.ethz.ch/files/bachem18scalable.pdf\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P_q9At3kxD8f",
    "outputId": "82a15e85-847f-43c8-effb-ab00bf7ac856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iJ1hzaGnmvUc",
    "outputId": "de7d65f4-216b-45de-caa3-5bc0b846eaf6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# loc = \"/content/gdrive/My\\ Drive/IITGn\\ Files/Semester\\ 7/IDS/Project/ploting_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWOm0IM27C2K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(all='warn')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "id": "4G1VMghsQ5st",
    "outputId": "040aecd3-9f27-435c-8d20-a1d0ecbc2c38"
   },
   "outputs": [],
   "source": [
    "class Levarage:\n",
    "    def __init__(self, data, mode='reduced'):\n",
    "        '''Assuming the datapoints are in rows'''\n",
    "        data\n",
    "        self.len = data.shape[0] # number \n",
    "        self.pdf = self._find_multinomial_distrib(data, mode) # saving pdf for sampling\n",
    "    \n",
    "    def sample_ix(self, percent, seed):\n",
    "        np.random.seed(seed)\n",
    "        '''samples percent points and returns thier indexes'''\n",
    "        num_of_sampes = int(self.len * percent / 100)\n",
    "        return np.random.choice(range(self.len), num_of_sampes, p=self.pdf)\n",
    "    \n",
    "    def _find_multinomial_distrib(self, data, mode):\n",
    "        q, r = np.linalg.qr(data, mode=mode)\n",
    "        q_row_norm2 = np.linalg.norm(q, ord=2, axis=1)**2 # assumed the rows are dpts\n",
    "        q_fnorm = np.linalg.norm(q, ord='fro')**2\n",
    "        return q_row_norm2 / q_fnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIE3HLHg7HK8"
   },
   "outputs": [],
   "source": [
    "class Sampling:\n",
    "  '''def __init__(self): return'''\n",
    "\n",
    "  def new_objective(self, data, new_centres):\n",
    "    obj = 0\n",
    "    for point in data:\n",
    "      if point not in new_centres:\n",
    "        distance = [sum((point-i)**2) for i in new_centres]\n",
    "        obj += min(distance)\n",
    "    return obj\n",
    "\n",
    "  def sampling(self, data, percent = 4, seed=5):    #n x d \n",
    "    raise NotImplemented\n",
    "\n",
    "  def plot_objective(self, data):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5J1rXAduNAF"
   },
   "outputs": [],
   "source": [
    "class Lev(Sampling):\n",
    "  def sampling(self, data, percent=1, seed=5):\n",
    "    lev_sampler = Levarage(data)\n",
    "    ix = lev_sampler.sample_ix(percent=percent, seed=seed)\n",
    "    return data[ix]\n",
    "\n",
    "class Corsets(Sampling):\n",
    "  def sampling(self, data, percent = 40, seed = 1, debug=False):\n",
    "    size = percent\n",
    "    size = size/100\n",
    "    coreset = []\n",
    "    m = int(size*len(data))\n",
    "    if debug: print(\"Sampling using lightweight coresets....\")\n",
    "    if debug: print(\"---Finding the mean of the data (Feature-wise)---\")\n",
    "    mean = []\n",
    "    total_number = 0\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    total_number = len(data)\n",
    "\n",
    "    if debug: print(\"---Finding differences squared sum between the mean and data values---\")\n",
    "    distances_sum = np.zeros(len(data[0]))\n",
    "    distances = []\n",
    "\n",
    "    for datapoint in data:  \n",
    "        temp_distance = 0.0 \n",
    "        for i in range(len(datapoint)):\n",
    "            distances_sum[i] += abs(mean[i]-datapoint[i])\n",
    "            temp_distance += abs(mean[i]-datapoint[i])\n",
    "            distances.append((np.sum(np.abs(datapoint-mean)))**2)\n",
    "        total_distance = np.sum(distances)\n",
    "\n",
    "    if debug: print(\"---Creating q(x) probability array---\")\n",
    "    q = []\n",
    "    uniform_distribution = 0.5*(1/total_number)\n",
    "    for i in range(len(data)):\n",
    "        q.append(uniform_distribution+0.5*(distances[i]/total_distance))\n",
    "\n",
    "    if debug: print(\"---Sampling\",int(size*len(data)),\"points to be used in lightweight coreset\")\n",
    "    for i in range(len(q)):\n",
    "        weight = 1.0/(m*q[i])\n",
    "        q[i] = weight\n",
    "    if int(m) >= total_number:\n",
    "        coreset = np.array(range(len(data)))\n",
    "    else:\n",
    "        coreset = np.random.choice(np.array(list(range(len(data)))), m, p = q/sum(q))\n",
    "    if debug: print(\"Coreset creation complete.\\n\")\n",
    "    return data[coreset]\n",
    "\n",
    "\n",
    "class Rand(Sampling):\n",
    "  def sampling(self, data, percent = 1, seed=5):    #n x d \n",
    "    np.random.seed(seed)\n",
    "    sampling_idx = np.random.randint(0,len(data),size=int(percent*len(data)/100))\n",
    "    return data[sampling_idx]\n",
    "  \n",
    "class Volumetric(Sampling):\n",
    "  def sampling(self, data, percent=4, seed=3):\n",
    "    '''n x d matrix : data input'''\n",
    "    np.random.seed(seed)\n",
    "    X = np.transpose(data)\n",
    "    X = normalize(X)\n",
    "    Z = np.linalg.inv(np.dot(X,X.T))\n",
    "    Z = normalize(Z)\n",
    "    prob = np.zeros(X.shape[1])\n",
    "    n = X.shape[1]\n",
    "    number = percent/100*n\n",
    "    for i in range(X.shape[1]):\n",
    "       prob[i] = 1 - X[:,i].dot(Z).dot(X[:,i])\n",
    "    S = [i for i in range(n)]\n",
    "    prob=prob/prob.sum()\n",
    "    while(len(S)>number):\n",
    "      i = np.random.choice(np.arange(len(S)),p=prob)\n",
    "      S.remove(S[i])\n",
    "      v = Z.dot(X[:,i])/np.sqrt(prob[i])\n",
    "      prob = np.delete(prob,i)\n",
    "      for j in range(len(S)):\n",
    "         temp = prob[j] - (X[:,j].dot(v))**2\n",
    "      prob = prob/prob.sum()\n",
    "      Z = Z + v.dot(np.transpose(v))\n",
    "      Z = normalize(Z)\n",
    "    return data[S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c89v_I-H-dKE",
    "outputId": "9eacd592-65c5-4d74-a95e-bcc7e397b877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 74)\n"
     ]
    }
   ],
   "source": [
    "kdd_data_b =  pd.read_csv(\"./Dataset/bio_train.dat\",delimiter='\\t',header=None)\n",
    "kdd_data_b = np.array(kdd_data_b)\n",
    "chota = 5000 # full ke liye -1\n",
    "kdd_data = kdd_data_b[:chota,3:]\n",
    "print(kdd_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6SggaKvAQHH"
   },
   "outputs": [],
   "source": [
    "def get_costs(sampler,\n",
    "              name,\n",
    "              kdd_data,\n",
    "              n_cluster,\n",
    "              max_itern,\n",
    "              tolerance,\n",
    "              seeds,\n",
    "              percents):\n",
    "  \n",
    "  states = {}\n",
    "  for percent in percents:\n",
    "#     print (percents)\n",
    "    states['percent'+str(percent)] = {}\n",
    "    for seed in seeds:\n",
    "      km = KMeans(n_clusters = n_cluster,\n",
    "                  max_iter = max_itern,\n",
    "                  tol = tolerance,\n",
    "                  random_state = seed,\n",
    "                  init='random',\n",
    "                  n_jobs=-1)\n",
    "      sampled_data = sampler.sampling(kdd_data,\n",
    "                                      percent = percent,\n",
    "                                      seed = seed)\n",
    "      km.fit(sampled_data)\n",
    "      new_centres = km.cluster_centers_\n",
    "      post_sampling_cost = sampler.new_objective(kdd_data, new_centres)\n",
    "      states['percent'+str(percent)]['seed'+str(seed)] = post_sampling_cost\n",
    "  with open(name+\".pkl\", 'wb') as f:\n",
    "        pickle.dump(states, f)\n",
    "  return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqnSICE2AR9y"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  'kdd_data': kdd_data,\n",
    "  'n_cluster' : 5,\n",
    "  'max_itern' : 20,\n",
    "  'tolerance' : 1e-20,\n",
    "  'seeds' : (2, 4, 63, 45, 342, 5),\n",
    "  'percents' : tuple(i for i in range(1, 11)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_data = kdd_data\n",
    "n_cluster = 5\n",
    "max_itern = 20\n",
    "tolerance = 1e-20\n",
    "seeds = (2, 4, 63, 45, 342, 5)\n",
    "percents = tuple(i for i in range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p1 = Process(target=get_costs, args=(Rand(), 'random', kdd_data,\n",
    "                                                            n_cluster,\n",
    "                                                            max_itern,\n",
    "                                                            tolerance,\n",
    "                                                            seeds,\n",
    "                                                            percents,))\n",
    "    p2 = Process(target=get_costs, args=(Lev(), 'leverage', kdd_data,\n",
    "                                                            n_cluster,\n",
    "                                                            max_itern,\n",
    "                                                            tolerance,\n",
    "                                                            seeds,\n",
    "                                                            percents,))\n",
    "    p3 = Process(target=get_costs, args=(Corsets(), 'coreset', kdd_data,\n",
    "                                                            n_cluster,\n",
    "                                                            max_itern,\n",
    "                                                            tolerance,\n",
    "                                                            seeds,\n",
    "                                                            percents,))\n",
    "    p4 = Process(target=get_costs, args=(Volumetric(), 'volumetric', kdd_data,\n",
    "                                                            n_cluster,\n",
    "                                                            max_itern,\n",
    "                                                            tolerance,\n",
    "                                                            seeds,\n",
    "                                                            percents,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kLwULeaBPOX"
   },
   "source": [
    "def get_mean_std(new_dict):\n",
    "  df = pd.DataFrame(new_dict)\n",
    "  mean = df.mean(axis=0).values\n",
    "  std = df.std(axis=0).values\n",
    "  xdata = list(range(len(new_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "colab_type": "code",
    "id": "F4GTIhPXTIRm",
    "outputId": "caca18e3-e8bb-4639-a8ba-17386423d95d"
   },
   "source": [
    "std_flag = False\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, datas in zip(['red', 'grey', 'blue', 'green'], [rands, levs, cors, vols]):\n",
    "  xdata, ydata, dydata= get_mean_std(datas)\n",
    "  if not std_flag:\n",
    "    plt.plot(xdata, ydata, color=i)\n",
    "  else: \n",
    "    plt.errorbar(xdata, ydata, yerr = dydata, marker = '.', color = i)\n",
    "    plt.fill_between(xdata, ydata - dydata, ydata + dydata,\n",
    "                   color=i, alpha=0.2)\n",
    "\n",
    "plt.legend(('Random', 'Leverage', 'Corsets', 'Volumetric'))\n",
    "plt.xlabel('Sample %')\n",
    "plt.ylabel('Cost Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tmhnuu0Ll84"
   },
   "source": [
    "# Lightweight Coreset Sampling\n",
    "n_cluster = 5\n",
    "max_itern = 400\n",
    "tolerance = 1e-6\n",
    "sample_size = 0.6\n",
    "\n",
    "#km = KMeans(n_clusters = n_cluster, max_iter = max_itern, tol = tolerance)\n",
    "#km.fit(kdd_data)\n",
    "#pre_sampling_cost = km.inertia_\n",
    "\n",
    "LWC_sampled_data = sampler.light_weight_coresets(kdd_data, sample_size)\n",
    "km.fit(LWC_sampled_data)\n",
    "new_centres = km.cluster_centers_\n",
    "post_sampling_cost = sampler.new_objective(kdd_data, new_centres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gnk_6zCpK8Qv"
   },
   "source": [
    "pre_sampling_cost*10**(-11), post_sampling_cost*10**(-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq4CffgJL6Z5"
   },
   "source": [
    "np.abs(np.array([1,2,2])-np.array([4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOFlmxaH28nc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Sampling.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
